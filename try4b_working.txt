---
title: "try4"
output: html_document
---

Synopsis:  This exercise will quantify how well six subjects did in areas taken from accelerometers on the belt, forearm, arm and dumbell by using a model to predict the manner in which the subjects did the exercise.  

Description of how model was built:

Description of how cross validation is used:

Expectation of the out-of-sample error:

What were the reasons for the choices made?




```{r data_import, echo=FALSE}
if (!file.exists("pml-training.csv")) {
  download.file("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", 
                destfile = "pml-training.csv")
}
if (!file.exists("pml-testing.csv")) {
  download.file("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", 
                destfile = "pml-testing.csv")
}
```

```{r read_data_without_NAs}
pmlTrainingSet <- read.csv("pml-training.csv", header = TRUE, sep = ",",na.strings=c('NA','','#DIV/0!'))
pmlTestingSet <- read.csv("pml-testing.csv", header = TRUE, sep = ",",na.strings=c('NA','','#DIV/0!'))
```

```{r check_libraries,echo=FALSE}
# Check to see if all the packages that are needed are installed and loaded.
# If they aren't installed and/or loaded, load them. As it is not part of the overall model, code will not be revealed here.
require(caret)
pkgTest <- function(x)
{
  if (!require(x,character.only = TRUE))
  {
    install.packages(x,dependencies = TRUE)
       if(!require(x,character.only = TRUE)) stop("Package not found")
  }
}
library(caret) 
```

```{r partition_pmlTrainingSet}
# Set the seed for reproducibility
set.seed(10)

# We will split the training data into smaller parts (partition) so that we can create our model without having to touch the test data.
#   We will set the probability to 90%, which should give us a 15% error rate
inTrain <- createDataPartition(y=pmlTrainingSet$classe, p=0.9, list=FALSE) 
pmlTrainingSet1 <- pmlTrainingSet[inTrain, ] 
pmlTrainingSet2 <- pmlTrainingSet[-inTrain, ] # Whatever is left from pmlTrainingSet1
dim(pmlTrainingSet1)
```

```{r cross_validation}
# split data set into a bunch of smaller data sets using K-fold, which will later be used for cross validation
folds <- createFolds(y=pmlTrainingSet1$classe,k=10, list=TRUE, returnTrain=TRUE)
sapply(folds,length)
```

```{r rm_columns_with_mostlyNAs}
# We check if the mean of the values are greater than 95% blank and filter them out.
naMeanGT95 <- sapply(pmlTrainingSet1, function(x) mean(is.na(x))) > 0.95 
pmlTrainingSet1 <- pmlTrainingSet1[, naMeanGT95==F] 
```

```{r nearZeroVariation}
# We filter out all values that are nearly zero
nzv <- nearZeroVar(pmlTrainingSet1) 
pmlTrainingSet1 <- pmlTrainingSet1[, -nzv]  
```

```{r remove_unnesessary_columns}
# We run a colnames() to manually check which columns do not have meaningful data.
# X, user_name, raw_timestamp_part1, raw_timestamp_part2, cvtd_timestamp, new_window, num_window are not used in prediction.
pmlTrainingSet1 <- pmlTrainingSet1[, -(1:7)]  
```

```{r fit_model}
fitControl <- trainControl(method="cv", number=3, verboseIter=F) 
fit <- train(classe ~ ., data=pmlTrainingSet1, method="rf", trControl=fitControl) 
fit$finalModel 
preds <- predict(fit, newdata=pmlTrainingSet2) 
dim(preds)
```

